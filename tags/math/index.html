<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=49441&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Math | Jiajun, Shen</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:49441/tags/math/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:49441/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:49441/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:49441/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:49441/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:49441/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:49441/tags/math/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:49441/tags/math/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:49441/" accesskey="h" title="Jiajun, Shen (Alt + H)">Jiajun, Shen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:49441/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:49441/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:49441/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:49441/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:49441/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:49441/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Math
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">人工智能的数学基础
    </h2>
  </header>
  <div class="entry-content">
    <p>引言 经验风险$R_{emp}(f(u,x)=\frac{1}{n}\sum_{i=1}^n l(f(u_i,x),v_i)$ 期望风险(真实风险)：$R_{exp}(f(u, x)) = \mathbb{E}[l(f(u, x), v)]$ 结构风险模型：$R_{srm}\frac{1}{n}\sum_{i=1}^n l(f(u_i,x),v_i)&#43;\lambda J(f)$ 全体数据集最好算法$f^$，有限样本有限算法集最佳算法$\hat{h}_H$，全体数据有限算法最佳$h_H^$ 近似误差$R_{exp}(h_H^)-R^$，估算误差$R_{emp}(\hat{h}H) − R{exp}(h^∗_H)$ 最优化基础 广义实值函数 基本概念 广义实值函数：映射$\mathbb{R}^n$-&gt;广义函数空间$\mathbb{R}\cup{\pm\infty}$ $\alpha$-下水平集：$C_\alpha={x|f(x)\le\alpha}$，上方图$\mathrm{epi}$ $f = { (x, t) ∈ R^{n&#43;1} |f(x) ≤ t}$ $\alpha$-下水平集是闭集&lt;=&gt;下半连续&lt;=&gt;闭函数（上方图是闭集） 对偶范数$||y||*=sup{||x||\le1}x^Ty$ 梯度$\nabla f(x)=[\frac{\partial f}{\partial x_1}(x),…,\frac{\partial f}{\partial x_n}(x)]^T$，Hessian矩阵（$n\times n$）:$\nabla^2 f(x)$ 方向导数$\partial f(x;d)=\frac{\partial d}{\partial d}(x)=\lim_{\theta\rightarrow 0 }\frac{f(x&#43;\theta d)-f(x)}{\theta}=\nabla f(x)^T d$ 二阶方向导数$d^T\nabla^2 f(x)d$，Jacobi矩阵$[J(x)]_{ij}=\frac{\partial f_i}{\partial x_j}(x)$ 泰勒展开式：$f(x&#43;d)=f(x)&#43;\nabla f(x&#43;td)^T d=f(x)&#43;\nabla f(x)^T d&#43;\frac{1}{2}d^T\nabla^2 f(x&#43;td)d$ 凸性 凸集：$\eta x_1&#43;(1-\eta) x_2\in S$ 凸函数$f(\eta x_1 &#43;(1-\eta)x_2 \le \eta f(x_1)&#43;(1-\eta)f(x_2)$&lt;=&gt;$f(y)\ge f(x)&#43;\nabla f(x)^T(y-x)$&lt;=&gt;当且仅当在任意直线上是凸的 强凸：$\exists \mu&gt;0, f(y)\ge f(x)&#43;\nabla f(x)^T(y-x)&#43;\frac{1}{2}\mu ||x_2-x_1||_2^2$ 二阶条件$\nabla ^2 f(x)\ge 0$ 利普希茨连续 存在$L$，对于任意的$x,y\in \mathrm{dom} f$有：$||\nabla f(x)-\nabla f(y)|\le L||x-y|||$&lt;=&gt;$||\nabla ^2 f(x)||\le L, \forall x$ 凸函数，满足利普希茨条件，则$||\nabla f(x)-\nabla f(y)||^2\le L(x-y)^T(\nabla f(x)-\nabla f(y))$ #三个等价条件 次梯度 $f(y)\ge f(x)&#43;g^T (y-x)$，称$g$为次梯度，次梯度的集合为次微分$\partial f(x)$ 共轭函数 $f^*(y)=sup_x{y^Tx-f(x)}$ 性质：$f(x)&#43;f*(y)\ge x^Ty$，若$f$为闭函数，$f^{**}=f$ 优化算法与基本结构 算法基本结构 全局最小点$f(x^)&lt;f(x)$、严格全局最小点$x^\ne x$ 线搜索算法: 给定初始点x0∈R，置k:=0 若在 x[k] 点终止准则成立，则 x[k] 即为求得的最优解，终止; 否则，转步 3 根据方向计算规则，求得 x[k] 点搜索方向 d[k] 根据步长计算规则，求得搜索步长 η[k] 令x[k&#43;1]=x[k]&#43;η[k]*d[k]，置k:=k&#43;1，转步2 终止准则：$||g^k||\le \varepsilon$或$||x^{k&#43;1}-x^k||&lt;\varepsilon$或$||f(x^{k&#43;1})-f(x^k)||&lt;\varepsilon$ 收敛速度 若$\lim \frac{||x^{k&#43;1}-x^||}{||x^k-x^||}=\beta$，$0=\beta$超线性收敛，$0&lt;\beta&lt;1$线性收敛，$\beta=1$次线性收敛 二次收敛$\lim \frac{||x^{k&#43;1}-x^||}{||x^k-x^||^2}=\beta$(任意常数) 存在$\alpha\ge 1,\beta &gt;0$，当$k$足够大（与$\alpha \beta$无关），恒有$||x^{k&#43;1}-x^||\le \beta ||x^k-x^||^\alpha$ 如果他对于任意正定二次函数，从任意初始点出发，可以经有限步迭代求得极小点，我们就称该算法具有二次终止性 线搜索技术 精确线搜索法 Armojo准则：$d^k$是$x^k处$的下降方向，若$f(x^k&#43;\eta d^k)\le f(x^k)&#43;\rho \eta \nabla f(x^k)^T d^k$，则$\eta$满足Armijo准则 Armijo线搜索算法 选择初始步长 η，参数 ρ,γ ∈ (0,1)，初始化 η ← ηˆ 若 ηk 满足Armijo准则，则终止计算，得步长 ηk. 否则，转步 令ηk :=γηk，转步2. Goldstein准则：在Armijo准则基础上加上$f(x^k&#43;\eta d^k)\ge f(x^k)&#43;(1-\rho) \eta \nabla f(x^k)^T d^k$ 非精确线搜索 Wolfe 准则，它的核心思想有两个：目标函数值应该有足够的下降；可接受点处的切线斜率 ≥ 初始斜率的 σ 倍 在Armijo准则上加伤$\nabla f(x^k&#43;\eta d^k)^T d^k\ge \sigma \nabla f(x^k)^T d^k$ 非精确线搜索步长的存在性：$f(x^k &#43; ηd^k)$ 在 $η &gt; 0$ 时有下界，且 $∇f(x^k)^Td^k &lt; 0$ 最优化分支 线性与非线性规划 线性规划LP：在线性等式和不等式约束下最优化一个线性目标函数 如果约束和目标函数中有一个非线性的，则问题就称为非线性规划问题 二次规划QP 目标函数是变量的二次函数 Q半正定时QP是凸优化问题，可以用内点法在多项式时间内求解 锥优化CO 非负性条件 $x ≥ 0$ 用锥包含约束替换后得到的优化问题 二阶锥$x_1^2 ⩾ x_2^2 &#43;···&#43;x^2_n,x_1 ⩾ 0$ 对称半正定锥 $X=X^T$半正定 整数规划ILP 部分或全部变量取整数的优化问题 0-1规划 混合整数规划：既有连续变量又有整数约束变量时，问题称为混合整数线性规划 动态规划 涉及递推关系的计算方法，把问题分成阶段以便进行递推优化 最优化理论 Weierstrass 定理：条件任意成立一个：$\mathrm{dom f}$有界；存在常数$\bar{gamma}$使得下水平集$C_\gamma$是非空且有界的；$f$是强制的，即对于任意满足极限为$&#43;\infty$的点列都有其函数值趋向于$&#43;\infty$，则最优化问题的最小点集是非空且紧的 无约束可微优化问题 下降方向：如果存在$d$满足$\nabla f(x)^Td&lt;0$则$d$为一个下降方向。局部最优点处不能有下降方向。局部极小点$x^$满足$\nabla f(x^)=0$(一阶必要条件)，同时$\nabla^2f(x^*)$半正定（二阶必要条件），如果二阶连续可微，那么二阶必要条件是充分条件。 假设$f$#适当 且凸，则$x^$是局部极小点&lt;=&gt;$0\in \partial f(x^)$ 对于二阶连续可微的目标函数，梯度法、牛顿法、拟牛顿法在每一次迭代均能看做是构建局部的二次模型，梯度法可以看做利用 $(1/η^k)I$作为Hessian矩阵估计，牛顿类算法利用真实Hessian矩阵，拟牛顿利用真实Hessian矩阵或逆的估计构建模型。牛顿法收敛最快计算量存储量大，梯度法相对最慢。 梯度类算法 一般形式：$x^{k&#43;1}=x^k&#43;\eta_k d^k$，收敛速度：$L$-利普希茨连续时$0&lt;\eta&lt;\frac{1}{L}$时为$O(1/k)$，对强凸函数$0&lt;\eta&lt;\frac{1}{L&#43;\eta}$时Q-线性收敛 精确线搜索、数值线性搜索法 BB方法： 选取$min||\eta y^{k-1}-s^{k-1}||^2$或$min|| y^{k-1}-\eta^{-1}s^{k-1}||^2$的解 $s^{k-1}=x^{k&#43;1}-x^k$，$y^{k-1}=\nabla f(x^{k&#43;1})-\nabla f(x^k)$ 解分别为$\eta_{BB1}^k=\frac{(s^{k-1})^Ty^{k-1}} {(y^{k-1})^Ty^{k-1}}$，$\eta_{BB2}^k=\frac{(s^{k-1})^Ts^{k-1}} {(s^{k-1})^Ty^{k-1}}$ 通过$η_m ⩽η_k ⩽η_M$截断过大或过小的步长，也可以使用两种步长的凸组合 次梯度法 迭代格式：$x^{k&#43;1} = x^k − η^kg^k, g^k ∈ ∂f(x^k)$ 若 $0 \notin ∂f(x)$，那么对于任意 $x^∗ ∈ argmin_x f(x)$和任意 $g ∈ ∂f(x)$，存在步长 $η &gt; 0$ 使得$||x−ηg−x^||_2^2 &lt;||x−x^||_2^2$ 若至少存在一个极小点且次梯度有界，则$\sum \eta_k(f(x^k)-f(x^))\le \frac{1}{2}||x^0-x^||^2&#43;\frac{1}{2}\sum \eta_k^2 M^2$ 经典牛顿法 迭代格式：$x^{k&#43;1} = x^k − \nabla^2f(x^k)^{-1}\nabla f(x^k), g^k ∈ ∂f(x^k)$ 极小点处梯度为0，Hessian矩阵正定，则起始点足够近时，收敛是Q-二次的且梯度的范数Q-二次收敛到0 修正牛顿法 迭代格式：$x^{k&#43;1} = x^k &#43;\eta_k d^k$ 确定矩阵$E^k$使得$\nabla ^2 f(x^k)&#43;E^k$正定且条件数较小，求解$B^kd^k=-\nabla f(x^k)$，确定步长迭代。 非精确牛顿法 引入残差$r^k=\nabla^2 f(x^k)d^k&#43;\nabla f(x^k)$，$||r^k||\le \alpha_k||\nabla f(x^k)||$ 若存在$t&lt;1$使得$0&lt;\alpha_k&lt;t$则Q-线性收敛；若$\alpha_k$收敛到0，则Q-超线性收敛；若$\alpha_k=O(||\nabla f(x^k)||)$，则Q-二次收敛 拟牛顿条件 Hessian的近似矩阵满足$y^k=B^{k&#43;1}s^k$，逆矩阵$s^k=H^{k&#43;1}y^k$ 迭代格式：$x^{k&#43;1}=x^k&#43;\alpha_k d^k$，$d^k=-(B^k)^{-1}\nabla f(x^k)=-H^k\nabla f(x^k)$ SR1秩一更新 $B^{k&#43;1}=B^k&#43;\frac{(y^k-B^ks^k)(y^k-B^ks^k)^T}{(y^k-B^ks^k)^T s^k}$ $H^{k&#43;1}=H^k&#43;\frac{(s^k-H^ky^k)(s^k-H^ky^k)^T}{(s^k-H^ky^k)^T y^k}$ 秩二更新 BFGS(相当于在满足割线方程的对称矩阵中找到离 $H^k$ 最近的矩阵) 利用割线方程$Ws^k=y^k$ $B^{k&#43;1}=B^k&#43;\frac{y^k(y^k)^T}{(s^k)^T y^k}-\frac{B^k s^k(B^ks^k)^T}{(s^k)^T B^ks^k}$ $H^{k&#43;1}=(I-\rho_k y^k(s^k)^T)^TH^{k}(I-\rho_k y^k(s^k)^T)&#43;\rho_ks^k(s^k)^T, \rho=\frac{1}{s^T y}$ DFP方法，和BFGS为对偶关系 $Wy^k=s^k$ 收敛性质 Zoutendijk 条件：满足Wolfe准则的一般迭代格式，有下界、连续可微、梯度利普希茨连续，则$\sum_{k=0}^\infty \cos^2(\theta_k)||\nabla f(x^k)||^2&lt;\infty$，$\cos\theta_k=\frac{-\nabla f(x^k)^T d^k}{||\nabla f(x^k)^T ||||d^k||}$ BFGS 全局收敛性：初始矩阵$B^0$对称正定，目标函数连续可微，对$f(x^0)$下水平集凸，且存在正数$m$以及$M$对任意$x,z$有$m||z||^2\le z^T \nabla ^2 f(x)z \le M||z||^2$，则 BFGS 格式结合 Wolfe 线搜索的拟牛顿算法全局收敛到极小值点 BFGS 收敛速度：目标二阶连续可微，最优点邻域Hessian矩阵利普希茨连续，BFGS收敛，误差之和小于正无穷，则Q-超线性收敛 约束优化最优性理论 拉格朗日函数$L(x,\lambda,\nu)=f(x)&#43;\sum_{i\in I} \lambda_i c_i(x)&#43;\sum_{i \in E} \nu_i c_i(x)$ 对偶函数$g(\lambda, \nu)=\inf_x L(x,\lambda,\nu)$是凸函数，给出原优化问题的下界$g(\lambda,\nu)\le p^*$ 最优下界$\max g(\lambda,\nu)=max_{\lambda\ge 0,v}\inf_x L(x,\lambda,\nu)$ $domg = {(λ,ν) | λ ≥ 0,g(λ,ν) &gt; −∞}$，当 $(λ, ν) ∈ \mathrm{dom} g$ 时，称为对偶可行解，对偶问题的最优值为 $q^∗$.称 $p^∗ − q^∗(≥ 0)$ 为对偶间隙，对偶间隙为零，则强对偶原理成立 拉格朗日函数不动点$\nabla_x L(x^,\lambda_1^)=0$是必需但不充分的 某点$x^$不存在一阶可行下降方向时，$\nabla_x L(x^,\lambda_1^)=0,\lambda_1^\ge 0$且(互补松弛条件：)$\lambda_1^c_1(x^)=0$ 切锥$T_X(x)$：切向量$d=\lim_{k\rightarrow \infty}\frac{z_k-x}{t_k}$的集合，最优化要求切锥(可行方向集合)不包含使得目标函数值下降的方向 几何最优性条件：对局部极小点的可行点，目标和约束函数可微，则$d^T\nabla f(x^)\ge 0, \forall d \in T_X(x^)$&lt;=&gt;$T_X(x^)\cap{d|\nabla f(x^)^T d&lt;0}=\varnothing$ 线性化可行锥：$F(x)={d|d^T∇c_i(x) = 0, ∀ i ∈ E； d^T∇c_i(x)≤0,∀i∈A(x)∩I}$，积极集$A(x)=E∪{i∈I : c_i(x)=0}$ 线性无关约束规格：给定可行点 $x$ 及相应的积极集 $A(x)$. 如果积极集对应的约束函数的梯度, 即 $∇c_i(x), i ∈ A(x)$, 是线性无关的, 则称线性无关约束规格 (LICQ) 在点 $x$ 处成立，如果LICQ 成立，则有 $T_X (x) = F (x)$ MFCQ：如果存在一个向量 $w ∈ R^n$, 使得$∇c_i(x)^Tw &lt; 0, ∀i ∈ A(x) ∩ I;∇c_i(x)^Tw = 0, ∀i ∈ E$，并且等式约束对应的梯度集 ${∇c_i(x), i ∈ E}$是线性无关的，则称 MFCQ 在点 x 处成立 KKT条件：（如果局部极小点处有$T_X (x^∗) = F (x^∗)$） 稳定性条件$\nabla_x L(x^,\lambda^)=\nabla f(x^)&#43;\sum_{i\in I\cup E} \lambda_i^\nabla c_i(x^*)=0$ 原始可行性条件 $c_i (x^∗) = 0, ∀i ∈ E,$^ 原始可行性条件 $c_i (x^∗) ⩽ 0, ∀i ∈ I$ 对偶可行性条件 $λ^∗_i ⩾0,∀i∈I$ 互补松弛条件 $λ^∗_i c_i (x^∗) = 0,∀i ∈ I$ 二阶最优性条件： 二阶必要条件：如果局部最优解处处有$T_X (x^∗) = F (x^∗)$，$(x^,\lambda^)$满足KKT条件，则$d^T∇^2_{xx}L(x^∗,λ^∗)d ⩾ 0, ∀d ∈ C (x^∗,λ^∗)$ 二阶充分条件：$d^T∇^2_{xx}L(x^∗,λ^∗)d&gt;0, ∀d∈C(x^∗,λ^∗),d\ne0$，那么 $x^∗$ 为一个严格局部极小解. 约束优化方法 二次罚函数法 等式二次罚函数 $P_E(x,\sigma)=f(x)&#43;\frac{1}{2}\sigma \sum_{i\in E}c_i^2(x)，\sigma&gt;0$ 给定 σ1 &gt; 0,x0,k ← 1.罚因子增长系数 ρ &gt; 1; while 未达到收敛准则 do 以 xk 为初始点，求解 x[k&#43;1] = argmin PE (x, σk); 选取 σ[k&#43;1] = ρ*σ[k]; k ← k &#43; 1; end 收敛性： 设 $x^{k&#43;1}$ 是 $P_E (x, σ^k)$ 的全局极小解, $σ^k$ 单调上升趋于无穷, 则 $x^k$ 的每个极限点$x^∗$都是原问题的全局极小解 $\sigma c_i\rightarrow -\lambda_i^*$（一定条件下） 不等式二次罚函数 $P_I(x,\sigma)=f(x)&#43;\frac{1}{2}\sigma \sum_{i\in I}\tilde{c}_i^2(x)，\sigma&gt;0, \tilde{c}_i(x)=\max{c_i(x),0}$ 一般约束的二次罚函数 $P(x,\sigma)=f(x)&#43;\frac{1}{2}\sigma (\sum_{i\in I}\tilde{c}i^2(x)&#43;\sum{i\in E}c_i^2(x))$ 内点罚函数（常用对数） $P_I(x,\sigma)=f(x)-\sigma \sum_{i\in I}\ln(-c_i(x))$( 罚因子逐渐缩小，系数$\rho$) 收敛性：$|\sigma_k\sum_{i \in I}(-c_i(x^{k&#43;1})|\le \varepsilon$（实际上极限为0） 精确罚函数法 $l_1$罚函数：$P(x,\sigma)=f(x)&#43;\frac{1}{2}\sigma (\sum_{i\in I}\tilde{c}i(x)&#43;\sum{i\in E}|c_i(x)|)$ 当罚因子充分大 $σ&gt;||λ^*||_∞$(不需要是正无穷) 时，原问题的极小值点就是罚函数的极小值点 增广拉格朗日函数法 等式约束 增广拉格朗日函数$L_\sigma(x,\lambda)=f(x)&#43;\sum_{i\in E}\lambda_i c_i(x)&#43;\frac{1}{2}\sigma \sum_{i\in E}c_i^2(x)$ 初始坐标、乘子、罚因子及其更新常数，约束违反常数，精度，迭代步数 for k=.. do 从初始点求解增广拉格朗日函数最小值解，精度条件：梯度范数小于精度 if 等式约束满足精度 then 返回近似解，终止 else 更新乘子、罚因子 end 罚因子更新$σ_{k&#43;1} = ρσ{k}$，乘子更新$λ^{k&#43;1}_i=λ^k_i&#43;σ_i c_i (x^{k&#43;1})$ 一般约束约束 引入松弛变量，$L(x,s,\lambda,\mu)=f(x)&#43;\sum_{i\in E}\lambda_i c_i(x)&#43; \sum_{i\in I}\mu_i (c_i(x)&#43;s_i)$，$s_i\ge 0$；$p(x,s)=\sum_{i\in E}c_i^2(x)&#43;\sum_{i \in I}(c_i(x)&#43;s_i)^2$ 增广拉格朗日函数：$L_\sigma (x,s,\lambda,\mu)=L&#43;p(x,s)$ 取最优的$s_i=\max{-\frac{\mu_i}{\sigma_k}-c_i(x),0}$，原问题等价于优化$L_\sigma (x,\lambda,\mu)$ 初始坐标、乘子、罚因子及其更新常数，约束违反常数e，精度，常数alpha和beta、迭代步数 for k=.. do 从初始点求解增广拉格朗日函数最小值解，精度条件：梯度范数小于精度 if 约束违反度小与ek then if 约束违反度小于违反度常数e 且梯度范数小于精度 then 返回近似解，终止 else 更新两个乘子、罚因子不变，减小精度条件和约束违反度 else 乘子不变，更新罚因子，调整误差和约束违反度 end 乘子更新$E:\lambda_i^{k&#43;1}=\lambda_i^k \sigma_k c_i(x^{k&#43;1})$，$I:\mu_i^{k&#43;1}=\max{\mu_i^k &#43;\sigma_k c_i(x^{k&#43;1}),0}$ 误差和约束违反度：$\eta_{k&#43;1}=\frac{\eta_k}{\sigma_{k&#43;1}}，\varepsilon_{k&#43;1}=\frac{\varepsilon_k}{\sigma_{k&#43;1}^\beta}$或$\eta_{k&#43;1}=\frac{1}{\sigma_{k&#43;1}}，\varepsilon_{k&#43;1}=\frac{1}{\sigma_{k&#43;1}^\alpha}$ 凸优化问题 交替方向乘子法ADMM 对于优化$f_1(x)&#43;f_2(x), A_1x_1&#43;A_2x_2=b$， 增广拉格朗日函数$L_\rho(x_1,x_2,y)=f_1(x_1)&#43;f_2(x_2)&#43;y^T(A_1x_1&#43;A_2x_2-b)&#43;\frac{\rho}{2}||A_1x_1&#43;A_2x_2-b||^2_2$， [[乘子更新]]$y^{k&#43;1}=y^k&#43;\tau\rho (A_1x_1^{k&#43;1}&#43;A_2x_2^{k&#43;1}-b)$ 交替求极小：$x_1^{k&#43;1}=\argmin L_\rho (x_1,x_2^k,y^k)$；$x_2^{k&#43;1}=\argmin L_\rho (x_1^{k&#43;1},x_2,y^k)$；[[乘子更新]] 随机一阶优化方法 随机梯度类算法 随机梯度法 迭代格式$x^{k&#43;1}=x^k-\eta_k \nabla f_{ik}(x^k)$ 小批量随机梯度法 迭代格式$x^{k&#43;1}=x^k-\eta\nabla f _{S_k}(x^k), \nabla f {S_k}(x^k)=\frac{1}{|S_k|}\sum{i\in S_k }\nabla f_i(x^k)$ 随机动量法 迭代格式：$v^k=\beta_k v^{k-1}&#43;\nabla f_{i_k}(x^k), x^{k&#43;1}=x^k-\eta_k v^k$ 等价于重球法$x^{k&#43;1}=x^k-\eta_k \nabla f_{i_k}(x^k)&#43;\hat{\beta}_k(x^k-x^{k-1})$ 随机次梯度法 迭代格式： $x^{k&#43;1} = x^k − η_kg^k, g^k ∈ ∂f_{i_k} (x^k)$, 当满足$\sum \eta_k =&#43;\infty, \frac{\sum_{1\sim K-1}}{\eta_k^2}{\sum_{1\sim K-1}}{\eta_k}\rightarrow 0$时算法收敛 函数的渐近表现很脆弱，这种算法结构很难实现并行化，当问题规模较大时，算法执行时间长 随机方差缩减类方法 $SGD_$：$x^{k&#43;1}=x^k-\eta(\nabla f_{i_k}(x^k)-\nabla f_{i_k}(x^))$ 动态抽样方法 范数测试、内积测试、锐角测试 分层抽样方法：将训练样本分类，每一类独立采样子集 $x^{k&#43;1}=x^k-\frac{\eta_k}{n}\sum_{i=1}^{t}\frac{n_i^k}{b_i^k}\sum_{s\in B_i^k} \nabla f_s(x^k)$ SAG算法 全梯度的估计$\bar{g}^k=\frac{1}{n}\sum_{j=1}^n v_j^k$ 迭代时$v_j^{k&#43;1}=\nabla f_{i_k}(x_k)\quad \mathrm{if} j=i_k ,\mathrm{else}: v_j^k$，即更新之后将抽取的样本对应的随机梯度改为当前的随机梯度值 由于每次只有一部分改变，可以写成$\bar{g}^k=\bar{g}^{k-1}-\frac{1}{n}v_{i_k}^{k-1}&#43;\frac{1}{n}v_{i_k}^k$ SAGA算法 SAGA 算法选择一个参考点$\bar{x}^i,v_i=\nabla f_i(\bar{x}^i)$ $g^k=\nabla f_{i_k}(x^k)-\nabla f_{i_k}(\bar{x}^{i_k})&#43;\frac{1}{n}\sum_{j=1}^n \nabla f_j(\bar{x}_j)$ x 线性收敛速度 SVRG算法 每经过几次迭代之后设置检查点，计算全梯度作为参考 $\nabla f(x^j)=\frac{1}{n}\sum_{i=1}^n \nabla f_i(x^j)$ $v^k=\nabla f_{i_k}(x^k)-(\nabla f_{i_k}(x^j)-\nabla f(x^j))$ 对于参考点的函数值期望的意义下线性收敛速度 随机递归梯度法SARAH 梯度估计的更新$v^k=\nabla f_{i_k}(x^k)-\nabla f_{i_k}(x^{k-1})&#43;v^{k-1} , v^0=$全梯度 不是无偏估计 带BB步长的方差缩减类 AdaGrad $x^{k&#43;1}=x^k-\frac{\eta}{\sqrt{G^k&#43;\varepsilon 1_n}}\circ g^k$ $G^{k&#43;1}=G^k&#43;g^k \circ g^k$ RMSProp $x^{k&#43;1}=x^k-\frac{\eta}{\sqrt{M^k&#43;\varepsilon 1_n}}\circ g^k$ $G^{k&#43;1}=\rho G^k&#43;(1-\rho)g^{k&#43;1} \circ g^{k&#43;1}$ Adam 梯度$g^k=\nabla f_i (x^k)$ 一阶矩$S^k=\rho_1 S^{k-1}&#43;(1-\rho_1)g^k$ 二阶矩$M^k=\rho_2 M^{k-1}&#43;(1-\rho_2)g^k\circ g^k$ 一阶矩修正$\hat{S}^k=\frac{S^k}{1-\rho_1^k}$ 二阶矩修正$\hat{M}^k=\frac{M^k}{1-\rho_2^k}$ $x^{k&#43;1}=x^k-\frac{\eta}{\sqrt{\hat{M}^k&#43;\varepsilon 1_n}}\circ \hat{S}^k$ AdaBelief 修改二阶矩的计算 $Q^k=\rho_2 Q^{k-1}&#43;(1-\rho_2)(g^k-S^k)\circ (g^k-S^k)$ 修正二阶矩偏差时加入额外的$\varepsilon$保证有下界 $\hat{Q}^k=\frac{Q^k&#43;\varepsilon}{1-\rho_2^k}$ AdaBelief 算法在“大梯度，小曲率”情况下有优势 </p>
  </div>
  <footer class="entry-footer"><span title='2024-10-19 16:34:43 +0800 CST'>October 19, 2024</span></footer>
  <a class="entry-link" aria-label="post link to 人工智能的数学基础" href="http://localhost:49441/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:49441/">Jiajun, Shen</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
