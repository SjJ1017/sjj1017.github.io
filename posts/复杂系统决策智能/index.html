<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>复杂系统决策智能 | Jiajun, Shen</title>
<meta name="keywords" content="AI, Control">
<meta name="description" content="绪论

最优化问题

分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态


函数优化问题与组合优化问题
P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题
计算智能方法

逻辑主义、行为主义、联结主义
神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索）



神经网络

基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值
基本原理：输入层、加权和、阈值函数、输出层
单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络
学习算法：

有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入
调整连接权系数和阈值）
梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单

最速下降法


BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整
BRF神经网络：

求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。
求解方差
计算隐含层和输出层之间的权值


卷积神经网络



模糊逻辑

模糊集合

可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u)
Zadeh表示法$A=\sum \frac{f_A(u)}{u}|A=\int_u \frac{f_A(u)}{u}$
序对表示法$A={(u,f_A(u))|u\in U}$
子集：对任意元素都有$f_A(u)&lt;f_B(u)$则$A$是$B$的子集
交：取最小，并：取最大，补：用1减
隶属度函数呈单峰馒头形（(凸模糊集合）
模糊变量的标称值选择一般取3—9个为宜，通常取奇数 (平衡)——在“零”、“适中”或者“合适”集合的两边语言值通常取对称(如速度适中，一边取“速度高”，一般另一 边取“速度低”，满足对称)。
隶属度函数要符合人们的语义顺序，避免不恰当的重叠，在相同的论域上使用的具有语义顺序关系的若干标称的模 糊集合，应该合理的排列。下面的排列是错误的。
模糊统计法：隶属频率=属于A的次数/总次数
例证法：由已知的有限个隶属函数的值， 来估计论域U上的模糊子集A的隶属函数。
专家经验法、二元对比排序法
大概三类图形：

左大右小的偏小型下降函数(Z函数
左小右大的偏大型上升函数(S函数)
对称型凸函数(II函数)




模糊关系

$U\times V={(u,v)|u\in U,v\in V}, (u,v)\rightarrow{}R(u,v)$
模糊矩阵
模糊关系的复合
极大-极小复合$R_1R_2={[(x,z),\max_y \min[\mu_{R1}(x,y),\mu_{R2}(y,z)]]}$($R_1,R_2$在$X\times Y$和$Y\times Z$)
极大-乘积复合$R_1R_2={[(x,z),\max_y [\mu_{R1}(x,y)*\mu_{R2}(y,z)]]}$


模糊推理

语言变量的取值就是模糊集合。语言算子
T(年纪)={年轻，不年轻，不很年轻,&hellip;, 中年，不是中年,&hellip;,年老，非常年老,&hellip;, 不年轻也不老,&hellip;.}，其中“年纪”是语言变量。
(x,T(x),X,G,M)：其中x是语言变量名;T(x)为语言变量x的语言值或语言术语集合;X为语言变量x的论域;G为产生T(x)中术语的句法规则，用于产生语言变量值的;M是赋予每 个语言值A以含义M(A)的语法规则，即隶属度函数。
模糊推理是通过模糊规则将输入转化为输出的过程。在模糊推理中，小前提没有必要与大前提的前件 一致(A与C不必完全一致)，结论没有必要与大前提的后件一致(B与D不必完全一致)。



遗传算法

模式：模式指群体中编码的某些位置具有相似结构的染色体集合，模式的阶指模式中具有确定取值的基因个数，模式的定义长度指模式中第一个具有确定取值的基因到最后一个具有确定取值的基因的距离 (把中间的空格当作距离)
染色体编码：

$2^L=\frac{U_{max}-U_{min}}{\delta}&#43;1$，$U=U_{min}&#43;\frac{(U_{max}-U_{min})X}{2^L-1}$


群体初始化

随机数初始化


适应性评价

评估函数用于评估各个染色体的适应值，进而区分优劣


选择算子

轮盘赌方法选择，选中概率与适应度大小成正比$P_i=\frac{F(x_i)}{\sum F(x_i)}$
选择概率和积累概率


交配算子

交配概率$P_c$
将选择出的种群中的M个个体以随机的方式组成 M/2对配对个体组，交配操作就是在这些配对个体组中的两个个体之间进行&mdash;随机配对
单点交叉（选一个交叉点，一半交叉）、多点交叉、均匀交叉（对每一个基因位随机交换或不交换）


变异算子

变异概率$P_m$
与个体编码串长度等长的屏蔽字，确定哪些位变异



粒子群算法

初始化，随机初始化速度和位置
速度位置更新，惯量权重$\omega$，加速系数$c_i$，随机数$r_i$

$v_i=\omega v_i &#43;c_1r_1(p_{Best_i}-x_i) &#43;c_2r_2(g_{Best}-x_i)$
$x_i=x_i&#43;v_i$


评估粒子的适应度函数值，更新粒子最优位置和全局最优位置
结束条件：gBest差值小于精度

贝叶斯网络

全概率公式、贝叶斯公式

贝叶斯网络

原因节点：没有连线以他们为终点



贝叶斯网络的预测

自顶向下的过程
把证据向量输入到贝叶斯网络B中;
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续下面的步骤
如果它的所有父结点中有一个没有处理过，则不处理这个结点(保证自顶向下);否则，继续下面的步骤
根据结点n的所有父结点的概率以及条件概率或联合条件概 率计算结点n的概率分布，并把结点n标记为已处理
重复步骤(2)~(4)共m次。此时，结点t的概率分布就是
它的发生/不发生的概率。算法结束。



贝叶斯网络诊断

把证据向量输入到贝叶斯网络B中
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续面的步骤
如果它的所有子结点中有一个没有处理过，则不处理这个结点(保证自底向上)；否则，继续下面的步骤
根据节点n所有子结点的概率以及条件概率或联合条件概率，根据条件概率公式，计算结点n的概率分布，并把结点n标记为已处理;
重复步骤共m次。此时，原因结点t的概率分布就是它的发生/不发生的概率。算法结束。



贝叶斯网络训练

在两个结点之间建立连线时，要防止环的出现，因为贝叶斯网络必须是无环图
通过历史数据获得贝叶斯网络中各结点的概率以及结点之间条件概率的过程



STATIC OPTIMIZATION

无约束优化问题

$L=\frac{1}{2}u^T Qu&#43;S^T u$=&gt;$u*=-Q^{-1}S$


等式约束优化

方法一：

$dL=L_u^T du&#43;L_x^T dx$,$df=f_udu&#43;f_xdx$
$dL/du=L_u-f_u^Tf_x^{-T}L_x=0$


方法二：

\[ \begin{bmatrix}  dL\df  \end{bmatrix} =\begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}\begin{bmatrix}  dx\du  \end{bmatrix}=0 \]
\[\begin{bmatrix}  1&amp;\lambda^T  \end{bmatrix} \begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}=0, \quad \frac{\partial L}{\partial f}|_{du=0}-\lambda \]


方法三：

$H(x,u,\lambda)=L(x,u)_\lambda^Tf(x,u)$
$H_u=H_x=H_\lambda=0$




Effect of Changes in Constraints

约束改变$\mathrm{d}f$，则$\mathrm{d}x=f_x^{-1}(I&#43;f_u C)\mathrm{d}f$，$\mathrm{d}u=-(L_{uu}^{f})^{-1}(H_{ux}-f^T_u f^{-T}x H{xx})f_x^{-1}\mathrm{d}f$



约束优化：

初始点$u$
确定$x$: $f(x,u)=0$
确定乘子$\lambda=-f_x^{-T}L_x$
确定梯度$H_u=L_u&#43;f_u^T\lambda$
更新$\Delta u=-\alpha H_u$
计算$\Delta L=H_u^T \Delta u$，根据要求回第二步。




动态规划方法

难点：离散化模型面临维数灾难、HJB 方程一般难以求解、HJB 方程对值函数有可微的要求
最优性原理：多级决策过程的最优策具有如下性质:不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。
动态规划求解最短路径，从终点开始向后求解。
动态规划求解离散最优控制

离散化时间：$t_k\in [t_0&#43;k\Delta t,t_0&#43;(k&#43;1)\Delta t]$
离散化状态方程$：\dot{x}(t)=f(x(t),u(t),t),x(t_0)=x_0$; $x(k&#43;1)=f_D(x(k),u(k),k)$
离散化性能指标：$J=h_D(x(N),N)&#43;\sum_{k=0}^{N-1}g_D(x(k),u(k),k)$
Bellman 方程

最优控制下的性能 $V(x_0,k_0)$，Bellman方程是充要条件：$V(x(k),k)=min_{u(k)\in U}{g_D(x(k),u(k),k)&#43;V(x(k&#43;1),k&#43;1) }$, $V(x(N),N)=h_D(x(N),N)$



直接迭代求解

从后往前依次求解$u(k)$



遍历离散状态和离散控制空间

将$x(k)$离散化为$x^0,&hellip;,x^{s-1}$，$u(k)=u^0,&hellip;,u^{c-1}$
$V(x(k), k) = min {g_D(x(k), u(k), k) &#43; V(x(k &#43; 1), k &#43; 1)}$
查表：直接寻找距离最近的
插值计算：不直接查表，使用插值近似



遍历当前和下时刻离散状态空间

每个时刻求解析解，只需要遍历离散化的状态$x(k),x(k&#43;1)$




连续$J(u,x_0,t_0)=h(x(x_f),t_f)&#43;\int_{t_0}^{t_f} g(x(t),u(t),t)\mathrm{d}t$

最优控制充要条件HJB方程：$-V_t(x(t),t)=\min H(x(t),u(t),V^T_x(x(t),t),t)$=&gt;$V_t&#43;\min_u{V_x^T \dot{x} &#43;g(x,u,t)     }=0$
边界条件$V(x(t_f),t_f)=h(x(t_f),t_f)$
没有终值可以增加一个罚函数项
值函数不可微的情况：分片考虑依然满足HJB方程，可验证是充分条件.



自适应动态规划

无限域最优控制问题动态规划，无法从终点开始
自适应动态规划方法由三个网络组成：模型网络、评判网络、执行网络
$x(k)$-&gt;Action Network-&gt;$u(k)$;
$u(k),x(k)$-&gt;Model Network-&gt;$x(k&#43;1)$;
$x(k&#43;1)$-&gt;Critic Network-&gt;$J(x(k&#43;1))$;

">
<meta name="author" content="">
<link rel="canonical" href="https://sjj1017.github.io/posts/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F%E5%86%B3%E7%AD%96%E6%99%BA%E8%83%BD/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://sjj1017.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://sjj1017.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://sjj1017.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://sjj1017.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://sjj1017.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://sjj1017.github.io/posts/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F%E5%86%B3%E7%AD%96%E6%99%BA%E8%83%BD/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

    <script type="text/javascript">
        document.addEventListener("DOMContentLoaded", function() {
          renderMathInElement(document.body, {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "\\[", right: "\\]", display: true},
              {left: "$", right: "$", display: false},
              {left: "\\(", right: "\\)", display: false},
            ],
          });
        });
      </script><meta property="og:title" content="复杂系统决策智能" />
<meta property="og:description" content="绪论

最优化问题

分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态


函数优化问题与组合优化问题
P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题
计算智能方法

逻辑主义、行为主义、联结主义
神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索）



神经网络

基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值
基本原理：输入层、加权和、阈值函数、输出层
单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络
学习算法：

有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入
调整连接权系数和阈值）
梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单

最速下降法


BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整
BRF神经网络：

求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。
求解方差
计算隐含层和输出层之间的权值


卷积神经网络



模糊逻辑

模糊集合

可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u)
Zadeh表示法$A=\sum \frac{f_A(u)}{u}|A=\int_u \frac{f_A(u)}{u}$
序对表示法$A={(u,f_A(u))|u\in U}$
子集：对任意元素都有$f_A(u)&lt;f_B(u)$则$A$是$B$的子集
交：取最小，并：取最大，补：用1减
隶属度函数呈单峰馒头形（(凸模糊集合）
模糊变量的标称值选择一般取3—9个为宜，通常取奇数 (平衡)——在“零”、“适中”或者“合适”集合的两边语言值通常取对称(如速度适中，一边取“速度高”，一般另一 边取“速度低”，满足对称)。
隶属度函数要符合人们的语义顺序，避免不恰当的重叠，在相同的论域上使用的具有语义顺序关系的若干标称的模 糊集合，应该合理的排列。下面的排列是错误的。
模糊统计法：隶属频率=属于A的次数/总次数
例证法：由已知的有限个隶属函数的值， 来估计论域U上的模糊子集A的隶属函数。
专家经验法、二元对比排序法
大概三类图形：

左大右小的偏小型下降函数(Z函数
左小右大的偏大型上升函数(S函数)
对称型凸函数(II函数)




模糊关系

$U\times V={(u,v)|u\in U,v\in V}, (u,v)\rightarrow{}R(u,v)$
模糊矩阵
模糊关系的复合
极大-极小复合$R_1R_2={[(x,z),\max_y \min[\mu_{R1}(x,y),\mu_{R2}(y,z)]]}$($R_1,R_2$在$X\times Y$和$Y\times Z$)
极大-乘积复合$R_1R_2={[(x,z),\max_y [\mu_{R1}(x,y)*\mu_{R2}(y,z)]]}$


模糊推理

语言变量的取值就是模糊集合。语言算子
T(年纪)={年轻，不年轻，不很年轻,&hellip;, 中年，不是中年,&hellip;,年老，非常年老,&hellip;, 不年轻也不老,&hellip;.}，其中“年纪”是语言变量。
(x,T(x),X,G,M)：其中x是语言变量名;T(x)为语言变量x的语言值或语言术语集合;X为语言变量x的论域;G为产生T(x)中术语的句法规则，用于产生语言变量值的;M是赋予每 个语言值A以含义M(A)的语法规则，即隶属度函数。
模糊推理是通过模糊规则将输入转化为输出的过程。在模糊推理中，小前提没有必要与大前提的前件 一致(A与C不必完全一致)，结论没有必要与大前提的后件一致(B与D不必完全一致)。



遗传算法

模式：模式指群体中编码的某些位置具有相似结构的染色体集合，模式的阶指模式中具有确定取值的基因个数，模式的定义长度指模式中第一个具有确定取值的基因到最后一个具有确定取值的基因的距离 (把中间的空格当作距离)
染色体编码：

$2^L=\frac{U_{max}-U_{min}}{\delta}&#43;1$，$U=U_{min}&#43;\frac{(U_{max}-U_{min})X}{2^L-1}$


群体初始化

随机数初始化


适应性评价

评估函数用于评估各个染色体的适应值，进而区分优劣


选择算子

轮盘赌方法选择，选中概率与适应度大小成正比$P_i=\frac{F(x_i)}{\sum F(x_i)}$
选择概率和积累概率


交配算子

交配概率$P_c$
将选择出的种群中的M个个体以随机的方式组成 M/2对配对个体组，交配操作就是在这些配对个体组中的两个个体之间进行&mdash;随机配对
单点交叉（选一个交叉点，一半交叉）、多点交叉、均匀交叉（对每一个基因位随机交换或不交换）


变异算子

变异概率$P_m$
与个体编码串长度等长的屏蔽字，确定哪些位变异



粒子群算法

初始化，随机初始化速度和位置
速度位置更新，惯量权重$\omega$，加速系数$c_i$，随机数$r_i$

$v_i=\omega v_i &#43;c_1r_1(p_{Best_i}-x_i) &#43;c_2r_2(g_{Best}-x_i)$
$x_i=x_i&#43;v_i$


评估粒子的适应度函数值，更新粒子最优位置和全局最优位置
结束条件：gBest差值小于精度

贝叶斯网络

全概率公式、贝叶斯公式

贝叶斯网络

原因节点：没有连线以他们为终点



贝叶斯网络的预测

自顶向下的过程
把证据向量输入到贝叶斯网络B中;
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续下面的步骤
如果它的所有父结点中有一个没有处理过，则不处理这个结点(保证自顶向下);否则，继续下面的步骤
根据结点n的所有父结点的概率以及条件概率或联合条件概 率计算结点n的概率分布，并把结点n标记为已处理
重复步骤(2)~(4)共m次。此时，结点t的概率分布就是
它的发生/不发生的概率。算法结束。



贝叶斯网络诊断

把证据向量输入到贝叶斯网络B中
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续面的步骤
如果它的所有子结点中有一个没有处理过，则不处理这个结点(保证自底向上)；否则，继续下面的步骤
根据节点n所有子结点的概率以及条件概率或联合条件概率，根据条件概率公式，计算结点n的概率分布，并把结点n标记为已处理;
重复步骤共m次。此时，原因结点t的概率分布就是它的发生/不发生的概率。算法结束。



贝叶斯网络训练

在两个结点之间建立连线时，要防止环的出现，因为贝叶斯网络必须是无环图
通过历史数据获得贝叶斯网络中各结点的概率以及结点之间条件概率的过程



STATIC OPTIMIZATION

无约束优化问题

$L=\frac{1}{2}u^T Qu&#43;S^T u$=&gt;$u*=-Q^{-1}S$


等式约束优化

方法一：

$dL=L_u^T du&#43;L_x^T dx$,$df=f_udu&#43;f_xdx$
$dL/du=L_u-f_u^Tf_x^{-T}L_x=0$


方法二：

\[ \begin{bmatrix}  dL\df  \end{bmatrix} =\begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}\begin{bmatrix}  dx\du  \end{bmatrix}=0 \]
\[\begin{bmatrix}  1&amp;\lambda^T  \end{bmatrix} \begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}=0, \quad \frac{\partial L}{\partial f}|_{du=0}-\lambda \]


方法三：

$H(x,u,\lambda)=L(x,u)_\lambda^Tf(x,u)$
$H_u=H_x=H_\lambda=0$




Effect of Changes in Constraints

约束改变$\mathrm{d}f$，则$\mathrm{d}x=f_x^{-1}(I&#43;f_u C)\mathrm{d}f$，$\mathrm{d}u=-(L_{uu}^{f})^{-1}(H_{ux}-f^T_u f^{-T}x H{xx})f_x^{-1}\mathrm{d}f$



约束优化：

初始点$u$
确定$x$: $f(x,u)=0$
确定乘子$\lambda=-f_x^{-T}L_x$
确定梯度$H_u=L_u&#43;f_u^T\lambda$
更新$\Delta u=-\alpha H_u$
计算$\Delta L=H_u^T \Delta u$，根据要求回第二步。




动态规划方法

难点：离散化模型面临维数灾难、HJB 方程一般难以求解、HJB 方程对值函数有可微的要求
最优性原理：多级决策过程的最优策具有如下性质:不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。
动态规划求解最短路径，从终点开始向后求解。
动态规划求解离散最优控制

离散化时间：$t_k\in [t_0&#43;k\Delta t,t_0&#43;(k&#43;1)\Delta t]$
离散化状态方程$：\dot{x}(t)=f(x(t),u(t),t),x(t_0)=x_0$; $x(k&#43;1)=f_D(x(k),u(k),k)$
离散化性能指标：$J=h_D(x(N),N)&#43;\sum_{k=0}^{N-1}g_D(x(k),u(k),k)$
Bellman 方程

最优控制下的性能 $V(x_0,k_0)$，Bellman方程是充要条件：$V(x(k),k)=min_{u(k)\in U}{g_D(x(k),u(k),k)&#43;V(x(k&#43;1),k&#43;1) }$, $V(x(N),N)=h_D(x(N),N)$



直接迭代求解

从后往前依次求解$u(k)$



遍历离散状态和离散控制空间

将$x(k)$离散化为$x^0,&hellip;,x^{s-1}$，$u(k)=u^0,&hellip;,u^{c-1}$
$V(x(k), k) = min {g_D(x(k), u(k), k) &#43; V(x(k &#43; 1), k &#43; 1)}$
查表：直接寻找距离最近的
插值计算：不直接查表，使用插值近似



遍历当前和下时刻离散状态空间

每个时刻求解析解，只需要遍历离散化的状态$x(k),x(k&#43;1)$




连续$J(u,x_0,t_0)=h(x(x_f),t_f)&#43;\int_{t_0}^{t_f} g(x(t),u(t),t)\mathrm{d}t$

最优控制充要条件HJB方程：$-V_t(x(t),t)=\min H(x(t),u(t),V^T_x(x(t),t),t)$=&gt;$V_t&#43;\min_u{V_x^T \dot{x} &#43;g(x,u,t)     }=0$
边界条件$V(x(t_f),t_f)=h(x(t_f),t_f)$
没有终值可以增加一个罚函数项
值函数不可微的情况：分片考虑依然满足HJB方程，可验证是充分条件.



自适应动态规划

无限域最优控制问题动态规划，无法从终点开始
自适应动态规划方法由三个网络组成：模型网络、评判网络、执行网络
$x(k)$-&gt;Action Network-&gt;$u(k)$;
$u(k),x(k)$-&gt;Model Network-&gt;$x(k&#43;1)$;
$x(k&#43;1)$-&gt;Critic Network-&gt;$J(x(k&#43;1))$;

" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sjj1017.github.io/posts/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F%E5%86%B3%E7%AD%96%E6%99%BA%E8%83%BD/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-10-19T16:34:43+08:00" />
<meta property="article:modified_time" content="2024-10-19T16:34:43+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="复杂系统决策智能"/>
<meta name="twitter:description" content="绪论

最优化问题

分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态


函数优化问题与组合优化问题
P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题
计算智能方法

逻辑主义、行为主义、联结主义
神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索）



神经网络

基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值
基本原理：输入层、加权和、阈值函数、输出层
单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络
学习算法：

有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入
调整连接权系数和阈值）
梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单

最速下降法


BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整
BRF神经网络：

求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。
求解方差
计算隐含层和输出层之间的权值


卷积神经网络



模糊逻辑

模糊集合

可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u)
Zadeh表示法$A=\sum \frac{f_A(u)}{u}|A=\int_u \frac{f_A(u)}{u}$
序对表示法$A={(u,f_A(u))|u\in U}$
子集：对任意元素都有$f_A(u)&lt;f_B(u)$则$A$是$B$的子集
交：取最小，并：取最大，补：用1减
隶属度函数呈单峰馒头形（(凸模糊集合）
模糊变量的标称值选择一般取3—9个为宜，通常取奇数 (平衡)——在“零”、“适中”或者“合适”集合的两边语言值通常取对称(如速度适中，一边取“速度高”，一般另一 边取“速度低”，满足对称)。
隶属度函数要符合人们的语义顺序，避免不恰当的重叠，在相同的论域上使用的具有语义顺序关系的若干标称的模 糊集合，应该合理的排列。下面的排列是错误的。
模糊统计法：隶属频率=属于A的次数/总次数
例证法：由已知的有限个隶属函数的值， 来估计论域U上的模糊子集A的隶属函数。
专家经验法、二元对比排序法
大概三类图形：

左大右小的偏小型下降函数(Z函数
左小右大的偏大型上升函数(S函数)
对称型凸函数(II函数)




模糊关系

$U\times V={(u,v)|u\in U,v\in V}, (u,v)\rightarrow{}R(u,v)$
模糊矩阵
模糊关系的复合
极大-极小复合$R_1R_2={[(x,z),\max_y \min[\mu_{R1}(x,y),\mu_{R2}(y,z)]]}$($R_1,R_2$在$X\times Y$和$Y\times Z$)
极大-乘积复合$R_1R_2={[(x,z),\max_y [\mu_{R1}(x,y)*\mu_{R2}(y,z)]]}$


模糊推理

语言变量的取值就是模糊集合。语言算子
T(年纪)={年轻，不年轻，不很年轻,&hellip;, 中年，不是中年,&hellip;,年老，非常年老,&hellip;, 不年轻也不老,&hellip;.}，其中“年纪”是语言变量。
(x,T(x),X,G,M)：其中x是语言变量名;T(x)为语言变量x的语言值或语言术语集合;X为语言变量x的论域;G为产生T(x)中术语的句法规则，用于产生语言变量值的;M是赋予每 个语言值A以含义M(A)的语法规则，即隶属度函数。
模糊推理是通过模糊规则将输入转化为输出的过程。在模糊推理中，小前提没有必要与大前提的前件 一致(A与C不必完全一致)，结论没有必要与大前提的后件一致(B与D不必完全一致)。



遗传算法

模式：模式指群体中编码的某些位置具有相似结构的染色体集合，模式的阶指模式中具有确定取值的基因个数，模式的定义长度指模式中第一个具有确定取值的基因到最后一个具有确定取值的基因的距离 (把中间的空格当作距离)
染色体编码：

$2^L=\frac{U_{max}-U_{min}}{\delta}&#43;1$，$U=U_{min}&#43;\frac{(U_{max}-U_{min})X}{2^L-1}$


群体初始化

随机数初始化


适应性评价

评估函数用于评估各个染色体的适应值，进而区分优劣


选择算子

轮盘赌方法选择，选中概率与适应度大小成正比$P_i=\frac{F(x_i)}{\sum F(x_i)}$
选择概率和积累概率


交配算子

交配概率$P_c$
将选择出的种群中的M个个体以随机的方式组成 M/2对配对个体组，交配操作就是在这些配对个体组中的两个个体之间进行&mdash;随机配对
单点交叉（选一个交叉点，一半交叉）、多点交叉、均匀交叉（对每一个基因位随机交换或不交换）


变异算子

变异概率$P_m$
与个体编码串长度等长的屏蔽字，确定哪些位变异



粒子群算法

初始化，随机初始化速度和位置
速度位置更新，惯量权重$\omega$，加速系数$c_i$，随机数$r_i$

$v_i=\omega v_i &#43;c_1r_1(p_{Best_i}-x_i) &#43;c_2r_2(g_{Best}-x_i)$
$x_i=x_i&#43;v_i$


评估粒子的适应度函数值，更新粒子最优位置和全局最优位置
结束条件：gBest差值小于精度

贝叶斯网络

全概率公式、贝叶斯公式

贝叶斯网络

原因节点：没有连线以他们为终点



贝叶斯网络的预测

自顶向下的过程
把证据向量输入到贝叶斯网络B中;
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续下面的步骤
如果它的所有父结点中有一个没有处理过，则不处理这个结点(保证自顶向下);否则，继续下面的步骤
根据结点n的所有父结点的概率以及条件概率或联合条件概 率计算结点n的概率分布，并把结点n标记为已处理
重复步骤(2)~(4)共m次。此时，结点t的概率分布就是
它的发生/不发生的概率。算法结束。



贝叶斯网络诊断

把证据向量输入到贝叶斯网络B中
对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续面的步骤
如果它的所有子结点中有一个没有处理过，则不处理这个结点(保证自底向上)；否则，继续下面的步骤
根据节点n所有子结点的概率以及条件概率或联合条件概率，根据条件概率公式，计算结点n的概率分布，并把结点n标记为已处理;
重复步骤共m次。此时，原因结点t的概率分布就是它的发生/不发生的概率。算法结束。



贝叶斯网络训练

在两个结点之间建立连线时，要防止环的出现，因为贝叶斯网络必须是无环图
通过历史数据获得贝叶斯网络中各结点的概率以及结点之间条件概率的过程



STATIC OPTIMIZATION

无约束优化问题

$L=\frac{1}{2}u^T Qu&#43;S^T u$=&gt;$u*=-Q^{-1}S$


等式约束优化

方法一：

$dL=L_u^T du&#43;L_x^T dx$,$df=f_udu&#43;f_xdx$
$dL/du=L_u-f_u^Tf_x^{-T}L_x=0$


方法二：

\[ \begin{bmatrix}  dL\df  \end{bmatrix} =\begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}\begin{bmatrix}  dx\du  \end{bmatrix}=0 \]
\[\begin{bmatrix}  1&amp;\lambda^T  \end{bmatrix} \begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}=0, \quad \frac{\partial L}{\partial f}|_{du=0}-\lambda \]


方法三：

$H(x,u,\lambda)=L(x,u)_\lambda^Tf(x,u)$
$H_u=H_x=H_\lambda=0$




Effect of Changes in Constraints

约束改变$\mathrm{d}f$，则$\mathrm{d}x=f_x^{-1}(I&#43;f_u C)\mathrm{d}f$，$\mathrm{d}u=-(L_{uu}^{f})^{-1}(H_{ux}-f^T_u f^{-T}x H{xx})f_x^{-1}\mathrm{d}f$



约束优化：

初始点$u$
确定$x$: $f(x,u)=0$
确定乘子$\lambda=-f_x^{-T}L_x$
确定梯度$H_u=L_u&#43;f_u^T\lambda$
更新$\Delta u=-\alpha H_u$
计算$\Delta L=H_u^T \Delta u$，根据要求回第二步。




动态规划方法

难点：离散化模型面临维数灾难、HJB 方程一般难以求解、HJB 方程对值函数有可微的要求
最优性原理：多级决策过程的最优策具有如下性质:不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。
动态规划求解最短路径，从终点开始向后求解。
动态规划求解离散最优控制

离散化时间：$t_k\in [t_0&#43;k\Delta t,t_0&#43;(k&#43;1)\Delta t]$
离散化状态方程$：\dot{x}(t)=f(x(t),u(t),t),x(t_0)=x_0$; $x(k&#43;1)=f_D(x(k),u(k),k)$
离散化性能指标：$J=h_D(x(N),N)&#43;\sum_{k=0}^{N-1}g_D(x(k),u(k),k)$
Bellman 方程

最优控制下的性能 $V(x_0,k_0)$，Bellman方程是充要条件：$V(x(k),k)=min_{u(k)\in U}{g_D(x(k),u(k),k)&#43;V(x(k&#43;1),k&#43;1) }$, $V(x(N),N)=h_D(x(N),N)$



直接迭代求解

从后往前依次求解$u(k)$



遍历离散状态和离散控制空间

将$x(k)$离散化为$x^0,&hellip;,x^{s-1}$，$u(k)=u^0,&hellip;,u^{c-1}$
$V(x(k), k) = min {g_D(x(k), u(k), k) &#43; V(x(k &#43; 1), k &#43; 1)}$
查表：直接寻找距离最近的
插值计算：不直接查表，使用插值近似



遍历当前和下时刻离散状态空间

每个时刻求解析解，只需要遍历离散化的状态$x(k),x(k&#43;1)$




连续$J(u,x_0,t_0)=h(x(x_f),t_f)&#43;\int_{t_0}^{t_f} g(x(t),u(t),t)\mathrm{d}t$

最优控制充要条件HJB方程：$-V_t(x(t),t)=\min H(x(t),u(t),V^T_x(x(t),t),t)$=&gt;$V_t&#43;\min_u{V_x^T \dot{x} &#43;g(x,u,t)     }=0$
边界条件$V(x(t_f),t_f)=h(x(t_f),t_f)$
没有终值可以增加一个罚函数项
值函数不可微的情况：分片考虑依然满足HJB方程，可验证是充分条件.



自适应动态规划

无限域最优控制问题动态规划，无法从终点开始
自适应动态规划方法由三个网络组成：模型网络、评判网络、执行网络
$x(k)$-&gt;Action Network-&gt;$u(k)$;
$u(k),x(k)$-&gt;Model Network-&gt;$x(k&#43;1)$;
$x(k&#43;1)$-&gt;Critic Network-&gt;$J(x(k&#43;1))$;

"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sjj1017.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "复杂系统决策智能",
      "item": "https://sjj1017.github.io/posts/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F%E5%86%B3%E7%AD%96%E6%99%BA%E8%83%BD/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "复杂系统决策智能",
  "name": "复杂系统决策智能",
  "description": "绪论 最优化问题 分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态 函数优化问题与组合优化问题 P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题 计算智能方法 逻辑主义、行为主义、联结主义 神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索） 神经网络 基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值 基本原理：输入层、加权和、阈值函数、输出层 单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络 学习算法： 有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入 调整连接权系数和阈值） 梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单 最速下降法 BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整 BRF神经网络： 求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。 求解方差 计算隐含层和输出层之间的权值 卷积神经网络 模糊逻辑 模糊集合 可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u) Zadeh表示法$A=\\sum \\frac{f_A(u)}{u}|A=\\int_u \\frac{f_A(u)}{u}$ 序对表示法$A={(u,f_A(u))|u\\in U}$ 子集：对任意元素都有$f_A(u)\u0026lt;f_B(u)$则$A$是$B$的子集 交：取最小，并：取最大，补：用1减 隶属度函数呈单峰馒头形（(凸模糊集合） 模糊变量的标称值选择一般取3—9个为宜，通常取奇数 (平衡)——在“零”、“适中”或者“合适”集合的两边语言值通常取对称(如速度适中，一边取“速度高”，一般另一 边取“速度低”，满足对称)。 隶属度函数要符合人们的语义顺序，避免不恰当的重叠，在相同的论域上使用的具有语义顺序关系的若干标称的模 糊集合，应该合理的排列。下面的排列是错误的。 模糊统计法：隶属频率=属于A的次数/总次数 例证法：由已知的有限个隶属函数的值， 来估计论域U上的模糊子集A的隶属函数。 专家经验法、二元对比排序法 大概三类图形： 左大右小的偏小型下降函数(Z函数 左小右大的偏大型上升函数(S函数) 对称型凸函数(II函数) 模糊关系 $U\\times V={(u,v)|u\\in U,v\\in V}, (u,v)\\rightarrow{}R(u,v)$ 模糊矩阵 模糊关系的复合 极大-极小复合$R_1R_2={[(x,z),\\max_y \\min[\\mu_{R1}(x,y),\\mu_{R2}(y,z)]]}$($R_1,R_2$在$X\\times Y$和$Y\\times Z$) 极大-乘积复合$R_1R_2={[(x,z),\\max_y [\\mu_{R1}(x,y)*\\mu_{R2}(y,z)]]}$ 模糊推理 语言变量的取值就是模糊集合。语言算子 T(年纪)={年轻，不年轻，不很年轻,\u0026hellip;, 中年，不是中年,\u0026hellip;,年老，非常年老,\u0026hellip;, 不年轻也不老,\u0026hellip;.}，其中“年纪”是语言变量。 (x,T(x),X,G,M)：其中x是语言变量名;T(x)为语言变量x的语言值或语言术语集合;X为语言变量x的论域;G为产生T(x)中术语的句法规则，用于产生语言变量值的;M是赋予每 个语言值A以含义M(A)的语法规则，即隶属度函数。 模糊推理是通过模糊规则将输入转化为输出的过程。在模糊推理中，小前提没有必要与大前提的前件 一致(A与C不必完全一致)，结论没有必要与大前提的后件一致(B与D不必完全一致)。 遗传算法 模式：模式指群体中编码的某些位置具有相似结构的染色体集合，模式的阶指模式中具有确定取值的基因个数，模式的定义长度指模式中第一个具有确定取值的基因到最后一个具有确定取值的基因的距离 (把中间的空格当作距离) 染色体编码： $2^L=\\frac{U_{max}-U_{min}}{\\delta}+1$，$U=U_{min}+\\frac{(U_{max}-U_{min})X}{2^L-1}$ 群体初始化 随机数初始化 适应性评价 评估函数用于评估各个染色体的适应值，进而区分优劣 选择算子 轮盘赌方法选择，选中概率与适应度大小成正比$P_i=\\frac{F(x_i)}{\\sum F(x_i)}$ 选择概率和积累概率 交配算子 交配概率$P_c$ 将选择出的种群中的M个个体以随机的方式组成 M/2对配对个体组，交配操作就是在这些配对个体组中的两个个体之间进行\u0026mdash;随机配对 单点交叉（选一个交叉点，一半交叉）、多点交叉、均匀交叉（对每一个基因位随机交换或不交换） 变异算子 变异概率$P_m$ 与个体编码串长度等长的屏蔽字，确定哪些位变异 粒子群算法 初始化，随机初始化速度和位置 速度位置更新，惯量权重$\\omega$，加速系数$c_i$，随机数$r_i$ $v_i=\\omega v_i +c_1r_1(p_{Best_i}-x_i) +c_2r_2(g_{Best}-x_i)$ $x_i=x_i+v_i$ 评估粒子的适应度函数值，更新粒子最优位置和全局最优位置 结束条件：gBest差值小于精度 贝叶斯网络 全概率公式、贝叶斯公式 贝叶斯网络 原因节点：没有连线以他们为终点 贝叶斯网络的预测 自顶向下的过程 把证据向量输入到贝叶斯网络B中; 对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续下面的步骤 如果它的所有父结点中有一个没有处理过，则不处理这个结点(保证自顶向下);否则，继续下面的步骤 根据结点n的所有父结点的概率以及条件概率或联合条件概 率计算结点n的概率分布，并把结点n标记为已处理 重复步骤(2)~(4)共m次。此时，结点t的概率分布就是 它的发生/不发生的概率。算法结束。 贝叶斯网络诊断 把证据向量输入到贝叶斯网络B中 对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续面的步骤 如果它的所有子结点中有一个没有处理过，则不处理这个结点(保证自底向上)；否则，继续下面的步骤 根据节点n所有子结点的概率以及条件概率或联合条件概率，根据条件概率公式，计算结点n的概率分布，并把结点n标记为已处理; 重复步骤共m次。此时，原因结点t的概率分布就是它的发生/不发生的概率。算法结束。 贝叶斯网络训练 在两个结点之间建立连线时，要防止环的出现，因为贝叶斯网络必须是无环图 通过历史数据获得贝叶斯网络中各结点的概率以及结点之间条件概率的过程 STATIC OPTIMIZATION 无约束优化问题 $L=\\frac{1}{2}u^T Qu+S^T u$=\u0026gt;$u*=-Q^{-1}S$ 等式约束优化 方法一： $dL=L_u^T du+L_x^T dx$,$df=f_udu+f_xdx$ $dL/du=L_u-f_u^Tf_x^{-T}L_x=0$ 方法二： \\[ \\begin{bmatrix} dL\\df \\end{bmatrix} =\\begin{bmatrix} L_x^T\u0026amp;L_u^T\\f_x\u0026amp;f_u \\end{bmatrix}\\begin{bmatrix} dx\\du \\end{bmatrix}=0 \\] \\[\\begin{bmatrix} 1\u0026amp;\\lambda^T \\end{bmatrix} \\begin{bmatrix} L_x^T\u0026amp;L_u^T\\f_x\u0026amp;f_u \\end{bmatrix}=0, \\quad \\frac{\\partial L}{\\partial f}|_{du=0}-\\lambda \\] 方法三： $H(x,u,\\lambda)=L(x,u)_\\lambda^Tf(x,u)$ $H_u=H_x=H_\\lambda=0$ Effect of Changes in Constraints 约束改变$\\mathrm{d}f$，则$\\mathrm{d}x=f_x^{-1}(I+f_u C)\\mathrm{d}f$，$\\mathrm{d}u=-(L_{uu}^{f})^{-1}(H_{ux}-f^T_u f^{-T}x H{xx})f_x^{-1}\\mathrm{d}f$ 约束优化： 初始点$u$ 确定$x$: $f(x,u)=0$ 确定乘子$\\lambda=-f_x^{-T}L_x$ 确定梯度$H_u=L_u+f_u^T\\lambda$ 更新$\\Delta u=-\\alpha H_u$ 计算$\\Delta L=H_u^T \\Delta u$，根据要求回第二步。 动态规划方法 难点：离散化模型面临维数灾难、HJB 方程一般难以求解、HJB 方程对值函数有可微的要求 最优性原理：多级决策过程的最优策具有如下性质:不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。 动态规划求解最短路径，从终点开始向后求解。 动态规划求解离散最优控制 离散化时间：$t_k\\in [t_0+k\\Delta t,t_0+(k+1)\\Delta t]$ 离散化状态方程$：\\dot{x}(t)=f(x(t),u(t),t),x(t_0)=x_0$; $x(k+1)=f_D(x(k),u(k),k)$ 离散化性能指标：$J=h_D(x(N),N)+\\sum_{k=0}^{N-1}g_D(x(k),u(k),k)$ Bellman 方程 最优控制下的性能 $V(x_0,k_0)$，Bellman方程是充要条件：$V(x(k),k)=min_{u(k)\\in U}{g_D(x(k),u(k),k)+V(x(k+1),k+1) }$, $V(x(N),N)=h_D(x(N),N)$ 直接迭代求解 从后往前依次求解$u(k)$ 遍历离散状态和离散控制空间 将$x(k)$离散化为$x^0,\u0026hellip;,x^{s-1}$，$u(k)=u^0,\u0026hellip;,u^{c-1}$ $V(x(k), k) = min {g_D(x(k), u(k), k) + V(x(k + 1), k + 1)}$ 查表：直接寻找距离最近的 插值计算：不直接查表，使用插值近似 遍历当前和下时刻离散状态空间 每个时刻求解析解，只需要遍历离散化的状态$x(k),x(k+1)$ 连续$J(u,x_0,t_0)=h(x(x_f),t_f)+\\int_{t_0}^{t_f} g(x(t),u(t),t)\\mathrm{d}t$ 最优控制充要条件HJB方程：$-V_t(x(t),t)=\\min H(x(t),u(t),V^T_x(x(t),t),t)$=\u0026gt;$V_t+\\min_u{V_x^T \\dot{x} +g(x,u,t) }=0$ 边界条件$V(x(t_f),t_f)=h(x(t_f),t_f)$ 没有终值可以增加一个罚函数项 值函数不可微的情况：分片考虑依然满足HJB方程，可验证是充分条件. 自适应动态规划 无限域最优控制问题动态规划，无法从终点开始 自适应动态规划方法由三个网络组成：模型网络、评判网络、执行网络 $x(k)$-\u0026gt;Action Network-\u0026gt;$u(k)$; $u(k),x(k)$-\u0026gt;Model Network-\u0026gt;$x(k+1)$; $x(k+1)$-\u0026gt;Critic Network-\u0026gt;$J(x(k+1))$; ",
  "keywords": [
    "AI", "Control"
  ],
  "articleBody": "绪论 最优化问题 分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态 函数优化问题与组合优化问题 P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题 计算智能方法 逻辑主义、行为主义、联结主义 神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索） 神经网络 基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值 基本原理：输入层、加权和、阈值函数、输出层 单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络 学习算法： 有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入 调整连接权系数和阈值） 梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单 最速下降法 BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整 BRF神经网络： 求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。 求解方差 计算隐含层和输出层之间的权值 卷积神经网络 模糊逻辑 模糊集合 可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u) Zadeh表示法$A=\\sum \\frac{f_A(u)}{u}|A=\\int_u \\frac{f_A(u)}{u}$ 序对表示法$A={(u,f_A(u))|u\\in U}$ 子集：对任意元素都有$f_A(u)",
  "wordCount" : "246",
  "inLanguage": "en",
  "datePublished": "2024-10-19T16:34:43+08:00",
  "dateModified": "2024-10-19T16:34:43+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://sjj1017.github.io/posts/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F%E5%86%B3%E7%AD%96%E6%99%BA%E8%83%BD/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jiajun, Shen",
    "logo": {
      "@type": "ImageObject",
      "url": "https://sjj1017.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://sjj1017.github.io/" accesskey="h" title="Jiajun, Shen (Alt + H)">Jiajun, Shen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://sjj1017.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://sjj1017.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://sjj1017.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://sjj1017.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://sjj1017.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://sjj1017.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      复杂系统决策智能
    </h1>
    <div class="post-meta"><span title='2024-10-19 16:34:43 +0800 CST'>October 19, 2024</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e7%bb%aa%e8%ae%ba" aria-label="绪论">绪论</a></li>
                <li>
                    <a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" aria-label="神经网络">神经网络</a></li>
                <li>
                    <a href="#%e6%a8%a1%e7%b3%8a%e9%80%bb%e8%be%91" aria-label="模糊逻辑">模糊逻辑</a></li>
                <li>
                    <a href="#%e9%81%97%e4%bc%a0%e7%ae%97%e6%b3%95" aria-label="遗传算法">遗传算法</a></li>
                <li>
                    <a href="#%e7%b2%92%e5%ad%90%e7%be%a4%e7%ae%97%e6%b3%95" aria-label="粒子群算法">粒子群算法</a></li>
                <li>
                    <a href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c" aria-label="贝叶斯网络">贝叶斯网络</a><ul>
                        
                <li>
                    <a href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c-1" aria-label="贝叶斯网络">贝叶斯网络</a></li>
                <li>
                    <a href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c%e7%9a%84%e9%a2%84%e6%b5%8b" aria-label="贝叶斯网络的预测">贝叶斯网络的预测</a></li>
                <li>
                    <a href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c%e8%af%8a%e6%96%ad" aria-label="贝叶斯网络诊断">贝叶斯网络诊断</a></li>
                <li>
                    <a href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c%e8%ae%ad%e7%bb%83" aria-label="贝叶斯网络训练">贝叶斯网络训练</a></li></ul>
                </li>
                <li>
                    <a href="#static-optimization" aria-label="STATIC OPTIMIZATION">STATIC OPTIMIZATION</a></li>
                <li>
                    <a href="#%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92%e6%96%b9%e6%b3%95" aria-label="动态规划方法">动态规划方法</a><ul>
                        
                <li>
                    <a href="#%e7%9b%b4%e6%8e%a5%e8%bf%ad%e4%bb%a3%e6%b1%82%e8%a7%a3" aria-label="直接迭代求解">直接迭代求解</a></li>
                <li>
                    <a href="#%e9%81%8d%e5%8e%86%e7%a6%bb%e6%95%a3%e7%8a%b6%e6%80%81%e5%92%8c%e7%a6%bb%e6%95%a3%e6%8e%a7%e5%88%b6%e7%a9%ba%e9%97%b4" aria-label="遍历离散状态和离散控制空间">遍历离散状态和离散控制空间</a></li>
                <li>
                    <a href="#%e9%81%8d%e5%8e%86%e5%bd%93%e5%89%8d%e5%92%8c%e4%b8%8b%e6%97%b6%e5%88%bb%e7%a6%bb%e6%95%a3%e7%8a%b6%e6%80%81%e7%a9%ba%e9%97%b4" aria-label="遍历当前和下时刻离散状态空间">遍历当前和下时刻离散状态空间</a></li></ul>
                </li>
                <li>
                    <a href="#%e8%87%aa%e9%80%82%e5%ba%94%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92" aria-label="自适应动态规划">自适应动态规划</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="绪论">绪论<a hidden class="anchor" aria-hidden="true" href="#绪论">#</a></h3>
<ul>
<li>最优化问题
<ul>
<li>分类：变量个数、性质、约束、极值个数、目标个数、线性和非线性、确定/随机/模糊、静态/动态</li>
</ul>
</li>
<li>函数优化问题与组合优化问题</li>
<li>P（多项式时间内判定或解出）、NP（多项式时间内验证）、NPC问题</li>
<li>计算智能方法
<ul>
<li>逻辑主义、行为主义、联结主义</li>
<li>神经计算、模糊计算、进化计算（遗传、粒子群）、单点搜索（模拟退火、禁忌搜索）</li>
</ul>
</li>
<li>
<h3 id="神经网络">神经网络<a hidden class="anchor" aria-hidden="true" href="#神经网络">#</a></h3>
</li>
<li>基本特征：神经元及其联结、联结强度决定信号传递强弱、强度可以随着训练改变、信号可以起刺激作用或抑制作用、接收信号的累积效果决定状态、每个神经元有一个阈值</li>
<li>基本原理：输入层、加权和、阈值函数、输出层</li>
<li>单层感知器网络、前馈型网络、前馈内层互联网络、循环网（短期记忆特征，稳定，反馈信号引起的变化会减小并消失）、反馈型网络、全互联网络</li>
<li>学习算法：
<ul>
<li>有监督（实际输出与期望输出的偏差）和无监督（仅仅根据其输入
调整连接权系数和阈值）</li>
<li>梯度下降算法：一般来说，只能找到一个局部最小点(多解)，收敛速度较慢，算法结构简单
<ul>
<li>最速下降法</li>
</ul>
</li>
<li>BP神经网络：初始化网络权值、向前传播输入、反向误差传播、网络权值调整</li>
<li>BRF神经网络：
<ul>
<li>求取基函数中心：网络初始化，选取聚类中心，将输入的样本按最近邻分组，计算各个聚类集合的平均值得到新的聚类中心。</li>
<li>求解方差</li>
<li>计算隐含层和输出层之间的权值</li>
</ul>
</li>
<li>卷积神经网络</li>
</ul>
</li>
<li>
<h3 id="模糊逻辑">模糊逻辑<a hidden class="anchor" aria-hidden="true" href="#模糊逻辑">#</a></h3>
</li>
<li>模糊集合
<ul>
<li>可以部分地属于，对于U上一个元素u， f(u)叫做u对于模糊集的隶属度，也可写作 A(u)</li>
<li>Zadeh表示法$A=\sum \frac{f_A(u)}{u}|A=\int_u \frac{f_A(u)}{u}$</li>
<li>序对表示法$A={(u,f_A(u))|u\in U}$</li>
<li>子集：对任意元素都有$f_A(u)&lt;f_B(u)$则$A$是$B$的子集</li>
<li>交：取最小，并：取最大，补：用1减</li>
<li>隶属度函数呈单峰馒头形（(凸模糊集合）</li>
<li>模糊变量的标称值选择一般取3—9个为宜，通常取奇数 (平衡)——在“零”、“适中”或者“合适”集合的两边语言值通常取对称(如速度适中，一边取“速度高”，一般另一 边取“速度低”，满足对称)。</li>
<li>隶属度函数要符合人们的语义顺序，避免不恰当的重叠，在相同的论域上使用的具有语义顺序关系的若干标称的模 糊集合，应该合理的排列。下面的排列是错误的。</li>
<li>模糊统计法：隶属频率=属于A的次数/总次数</li>
<li>例证法：由已知的有限个隶属函数的值， 来估计论域U上的模糊子集A的隶属函数。</li>
<li>专家经验法、二元对比排序法</li>
<li>大概三类图形：
<ul>
<li>左大右小的偏小型下降函数(Z函数</li>
<li>左小右大的偏大型上升函数(S函数)</li>
<li>对称型凸函数(II函数)</li>
</ul>
</li>
</ul>
</li>
<li>模糊关系
<ul>
<li>$U\times V={(u,v)|u\in U,v\in V}, (u,v)\rightarrow{}R(u,v)$</li>
<li>模糊矩阵</li>
<li>模糊关系的复合</li>
<li>极大-极小复合$R_1R_2={[(x,z),\max_y \min[\mu_{R1}(x,y),\mu_{R2}(y,z)]]}$($R_1,R_2$在$X\times Y$和$Y\times Z$)</li>
<li>极大-乘积复合$R_1R_2={[(x,z),\max_y [\mu_{R1}(x,y)*\mu_{R2}(y,z)]]}$</li>
</ul>
</li>
<li>模糊推理
<ul>
<li>语言变量的取值就是模糊集合。语言算子</li>
<li>T(年纪)={年轻，不年轻，不很年轻,&hellip;, 中年，不是中年,&hellip;,年老，非常年老,&hellip;, 不年轻也不老,&hellip;.}，其中“年纪”是语言变量。</li>
<li>(x,T(x),X,G,M)：其中x是语言变量名;T(x)为语言变量x的语言值或语言术语集合;X为语言变量x的论域;G为产生T(x)中术语的句法规则，用于产生语言变量值的;M是赋予每 个语言值A以含义M(A)的语法规则，即隶属度函数。</li>
<li>模糊推理是通过模糊规则将输入转化为输出的过程。在模糊推理中，小前提没有必要与大前提的前件 一致(A与C不必完全一致)，结论没有必要与大前提的后件一致(B与D不必完全一致)。</li>
</ul>
</li>
<li>
<h3 id="遗传算法">遗传算法<a hidden class="anchor" aria-hidden="true" href="#遗传算法">#</a></h3>
</li>
<li><strong>模式</strong>：模式指群体中编码的某些位置具有相似结构的染色体集合，模式的阶指模式中具有确定取值的基因个数，模式的定义长度指模式中第一个具有确定取值的基因到最后一个具有确定取值的基因的距离 (把中间的空格当作距离)</li>
<li>染色体编码：
<ul>
<li>$2^L=\frac{U_{max}-U_{min}}{\delta}+1$，$U=U_{min}+\frac{(U_{max}-U_{min})X}{2^L-1}$</li>
</ul>
</li>
<li>群体初始化
<ul>
<li>随机数初始化</li>
</ul>
</li>
<li>适应性评价
<ul>
<li>评估函数用于评估各个染色体的适应值，进而区分优劣</li>
</ul>
</li>
<li>选择算子
<ul>
<li>轮盘赌方法选择，选中概率与适应度大小成正比$P_i=\frac{F(x_i)}{\sum F(x_i)}$</li>
<li>选择概率和积累概率</li>
</ul>
</li>
<li>交配算子
<ul>
<li>交配概率$P_c$</li>
<li>将选择出的种群中的M个个体以随机的方式组成 M/2对配对个体组，交配操作就是在这些配对个体组中的两个个体之间进行&mdash;随机配对</li>
<li>单点交叉（选一个交叉点，一半交叉）、多点交叉、均匀交叉（对每一个基因位随机交换或不交换）</li>
</ul>
</li>
<li>变异算子
<ul>
<li>变异概率$P_m$</li>
<li>与个体编码串长度等长的屏蔽字，确定哪些位变异</li>
</ul>
</li>
<li>
<h3 id="粒子群算法">粒子群算法<a hidden class="anchor" aria-hidden="true" href="#粒子群算法">#</a></h3>
</li>
<li>初始化，随机初始化速度和位置</li>
<li>速度位置更新，惯量权重$\omega$，加速系数$c_i$，随机数$r_i$
<ul>
<li>$v_i=\omega v_i +c_1r_1(p_{Best_i}-x_i) +c_2r_2(g_{Best}-x_i)$</li>
<li>$x_i=x_i+v_i$</li>
</ul>
</li>
<li>评估粒子的适应度函数值，更新粒子最优位置和全局最优位置</li>
<li>结束条件：gBest差值小于精度</li>
<li>
<h3 id="贝叶斯网络">贝叶斯网络<a hidden class="anchor" aria-hidden="true" href="#贝叶斯网络">#</a></h3>
</li>
<li>全概率公式、贝叶斯公式</li>
<li>
<h4 id="贝叶斯网络-1">贝叶斯网络<a hidden class="anchor" aria-hidden="true" href="#贝叶斯网络-1">#</a></h4>
<ul>
<li>原因节点：没有连线以他们为终点</li>
</ul>
</li>
<li>
<h4 id="贝叶斯网络的预测">贝叶斯网络的预测<a hidden class="anchor" aria-hidden="true" href="#贝叶斯网络的预测">#</a></h4>
<ul>
<li>自顶向下的过程</li>
<li>把证据向量输入到贝叶斯网络B中;</li>
<li>对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续下面的步骤</li>
<li>如果它的所有父结点中有一个没有处理过，则不处理这个结点(保证自顶向下);否则，继续下面的步骤</li>
<li>根据结点n的所有父结点的概率以及条件概率或联合条件概 率计算结点n的概率分布，并把结点n标记为已处理</li>
<li>重复步骤(2)~(4)共m次。此时，结点t的概率分布就是
它的发生/不发生的概率。算法结束。</li>
</ul>
</li>
<li>
<h4 id="贝叶斯网络诊断">贝叶斯网络诊断<a hidden class="anchor" aria-hidden="true" href="#贝叶斯网络诊断">#</a></h4>
<ul>
<li>把证据向量输入到贝叶斯网络B中</li>
<li>对于B中的每一个没处理过的结点n，如果它具有发生的事实(证据)，则标记它为已经处理过；否则继续面的步骤</li>
<li>如果它的所有子结点中有一个没有处理过，则不处理这个结点(保证自底向上)；否则，继续下面的步骤</li>
<li>根据节点n所有子结点的概率以及条件概率或联合条件概率，根据条件概率公式，计算结点n的概率分布，并把结点n标记为已处理;</li>
<li>重复步骤共m次。此时，原因结点t的概率分布就是它的发生/不发生的概率。算法结束。</li>
</ul>
</li>
<li>
<h4 id="贝叶斯网络训练">贝叶斯网络训练<a hidden class="anchor" aria-hidden="true" href="#贝叶斯网络训练">#</a></h4>
<ul>
<li>在两个结点之间建立连线时，要防止环的出现，因为贝叶斯网络必须是无环图</li>
<li>通过历史数据获得贝叶斯网络中各结点的概率以及结点之间条件概率的过程</li>
</ul>
</li>
<li>
<h3 id="static-optimization">STATIC OPTIMIZATION<a hidden class="anchor" aria-hidden="true" href="#static-optimization">#</a></h3>
</li>
<li>无约束优化问题
<ul>
<li>$L=\frac{1}{2}u^T Qu+S^T u$=&gt;$u*=-Q^{-1}S$</li>
</ul>
</li>
<li>等式约束优化
<ul>
<li>方法一：
<ul>
<li>$dL=L_u^T du+L_x^T dx$,$df=f_udu+f_xdx$</li>
<li>$dL/du=L_u-f_u^Tf_x^{-T}L_x=0$</li>
</ul>
</li>
<li>方法二：
<ul>
<li>\[ \begin{bmatrix}  dL\df  \end{bmatrix} =\begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}\begin{bmatrix}  dx\du  \end{bmatrix}=0 \]</li>
<li>\[\begin{bmatrix}  1&amp;\lambda^T  \end{bmatrix} \begin{bmatrix}  L_x^T&amp;L_u^T\f_x&amp;f_u  \end{bmatrix}=0, \quad \frac{\partial L}{\partial f}|_{du=0}-\lambda \]</li>
</ul>
</li>
<li>方法三：
<ul>
<li>$H(x,u,\lambda)=L(x,u)_\lambda^Tf(x,u)$</li>
<li>$H_u=H_x=H_\lambda=0$</li>
</ul>
</li>
</ul>
</li>
<li>Effect of Changes in Constraints
<ul>
<li>约束改变$\mathrm{d}f$，则$\mathrm{d}x=f_x^{-1}(I+f_u C)\mathrm{d}f$，$\mathrm{d}u=-(L_{uu}^{f})^{-1}(H_{ux}-f^T_u f^{-T}<em>x H</em>{xx})f_x^{-1}\mathrm{d}f$</li>
<li></li>
</ul>
</li>
<li>约束优化：
<ul>
<li>初始点$u$</li>
<li>确定$x$: $f(x,u)=0$</li>
<li>确定乘子$\lambda=-f_x^{-T}L_x$</li>
<li>确定梯度$H_u=L_u+f_u^T\lambda$</li>
<li>更新$\Delta u=-\alpha H_u$</li>
<li>计算$\Delta L=H_u^T \Delta u$，根据要求回第二步。</li>
</ul>
</li>
<li></li>
<li>
<h3 id="动态规划方法">动态规划方法<a hidden class="anchor" aria-hidden="true" href="#动态规划方法">#</a></h3>
</li>
<li>难点：离散化模型面临维数灾难、HJB 方程一般难以求解、HJB 方程对值函数有可微的要求</li>
<li>最优性原理：多级决策过程的最优策具有如下性质:不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。</li>
<li>动态规划求解最短路径，从终点开始向后求解。</li>
<li>动态规划求解离散最优控制
<ul>
<li>离散化时间：$t_k\in [t_0+k\Delta t,t_0+(k+1)\Delta t]$</li>
<li>离散化状态方程$：\dot{x}(t)=f(x(t),u(t),t),x(t_0)=x_0$; $x(k+1)=f_D(x(k),u(k),k)$</li>
<li>离散化性能指标：$J=h_D(x(N),N)+\sum_{k=0}^{N-1}g_D(x(k),u(k),k)$</li>
<li>Bellman 方程
<ul>
<li>最优控制下的性能 $V(x_0,k_0)$，Bellman方程是充要条件：$V(x(k),k)=min_{u(k)\in U}{g_D(x(k),u(k),k)+V(x(k+1),k+1) }$, $V(x(N),N)=h_D(x(N),N)$</li>
</ul>
</li>
<li>
<h4 id="直接迭代求解">直接迭代求解<a hidden class="anchor" aria-hidden="true" href="#直接迭代求解">#</a></h4>
<ul>
<li>从后往前依次求解$u(k)$</li>
</ul>
</li>
<li>
<h4 id="遍历离散状态和离散控制空间">遍历离散状态和离散控制空间<a hidden class="anchor" aria-hidden="true" href="#遍历离散状态和离散控制空间">#</a></h4>
<ul>
<li>将$x(k)$离散化为$x^0,&hellip;,x^{s-1}$，$u(k)=u^0,&hellip;,u^{c-1}$</li>
<li>$V(x(k), k) = min {g_D(x(k), u(k), k) + V(x(k + 1), k + 1)}$</li>
<li>查表：直接寻找距离最近的</li>
<li>插值计算：不直接查表，使用插值近似</li>
</ul>
</li>
<li>
<h4 id="遍历当前和下时刻离散状态空间">遍历当前和下时刻离散状态空间<a hidden class="anchor" aria-hidden="true" href="#遍历当前和下时刻离散状态空间">#</a></h4>
<ul>
<li>每个时刻求解析解，只需要遍历离散化的状态$x(k),x(k+1)$</li>
</ul>
</li>
</ul>
</li>
<li>连续$J(u,x_0,t_0)=h(x(x_f),t_f)+\int_{t_0}^{t_f} g(x(t),u(t),t)\mathrm{d}t$
<ul>
<li>最优控制充要条件HJB方程：$-V_t(x(t),t)=\min H(x(t),u(t),V^T_x(x(t),t),t)$=&gt;$V_t+\min_u{V_x^T \dot{x} +g(x,u,t)     }=0$</li>
<li>边界条件$V(x(t_f),t_f)=h(x(t_f),t_f)$</li>
<li>没有终值可以增加一个罚函数项</li>
<li>值函数不可微的情况：分片考虑依然满足HJB方程，可验证是充分条件.</li>
</ul>
</li>
<li>
<h3 id="自适应动态规划">自适应动态规划<a hidden class="anchor" aria-hidden="true" href="#自适应动态规划">#</a></h3>
</li>
<li>无限域最优控制问题动态规划，无法从终点开始</li>
<li>自适应动态规划方法由三个网络组成：模型网络、评判网络、执行网络</li>
<li>$x(k)$-&gt;Action Network-&gt;$u(k)$;</li>
<li>$u(k),x(k)$-&gt;Model Network-&gt;$x(k+1)$;</li>
<li>$x(k+1)$-&gt;Critic Network-&gt;$J(x(k+1))$;</li>
<li></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://sjj1017.github.io/tags/ai/">AI</a></li>
      <li><a href="https://sjj1017.github.io/tags/control/">Control</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://sjj1017.github.io/">Jiajun, Shen</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
